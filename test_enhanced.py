#!/usr/bin/env python3
"""
Quick Test for Enhanced DevO Chat
Tests both local and cloud AI functionality
"""

import os
import sys
from pathlib import Path

def test_basic_imports():
    """Test basic imports"""
    print("ğŸ§ª Testing basic imports...")
    
    try:
        import rich
        print("âœ… Rich available")
    except ImportError:
        print("âŒ Rich not available - install with: pip install rich")
        return False
    
    try:
        import click
        print("âœ… Click available")
    except ImportError:
        print("âŒ Click not available - install with: pip install click")
        return False
    
    return True

def test_gemini_api():
    """Test Gemini API functionality"""
    print("\nğŸŒ¤ï¸  Testing Gemini API...")
    
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âš ï¸  GEMINI_API_KEY not set - cloud AI unavailable")
        return False
    
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        
        # Test with a simple prompt
        model = genai.GenerativeModel("gemini-2.0-flash-exp")
        response = model.generate_content("Hello! Say 'AI test successful' if you can hear me.")
        
        if "successful" in response.text.lower():
            print("âœ… Gemini API working")
            return True
        else:
            print("âš ï¸  Gemini API responding but unexpected output")
            return False
            
    except Exception as e:
        print(f"âŒ Gemini API failed: {e}")
        return False

def test_local_ai():
    """Test local AI functionality"""
    print("\nğŸ§  Testing Local AI...")
    
    try:
        # Try importing torch
        import torch
        cuda_available = torch.cuda.is_available()
        print(f"âœ… PyTorch available (CUDA: {cuda_available})")
        
        if cuda_available:
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0) if gpu_count > 0 else "Unknown"
            print(f"ğŸš€ GPU: {gpu_name} ({gpu_count} device(s))")
    except ImportError:
        print("âš ï¸  PyTorch not available - install for local AI support")
        return False
    
    try:
        import transformers
        print("âœ… Transformers available")
    except ImportError:
        print("âš ï¸  Transformers not available - install for local AI support")
        return False
    
    # Test local LLM manager if available
    try:
        from local_llm import LocalLLMManager
        llm = LocalLLMManager()
        print("âœ… Local LLM manager available")
        
        # Test model listing
        models = llm.list_available_models()
        print(f"ğŸ“‹ Available models: {len(models)} configurations")
        
        return True
    except Exception as e:
        print(f"âš ï¸  Local LLM manager failed: {e}")
        return False

def test_enhanced_chat():
    """Test enhanced chat system"""
    print("\nğŸ’¬ Testing Enhanced Chat System...")
    
    try:
        # Test imports
        from chat_enhanced import EnhancedDevOChatSession
        print("âœ… Enhanced chat imports successful")
        
        # Test initialization (dry run)
        session = EnhancedDevOChatSession(
            api_key=os.getenv('GEMINI_API_KEY'),
            repo_path='.',
            use_local=True,
            local_model='codellama'
        )
        print("âœ… Enhanced chat session creation successful")
        
        return True
    except Exception as e:
        print(f"âŒ Enhanced chat test failed: {e}")
        return False

def test_automation():
    """Test automation features"""
    print("\nğŸ”§ Testing Automation Features...")
    
    try:
        from auto_setup import AutoSetupManager
        print("âœ… Auto setup manager available")
    except Exception as e:
        print(f"âš ï¸  Auto setup manager failed: {e}")
    
    try:
        from local_llm import AutomationManager, LocalLLMManager
        print("âœ… Automation manager available")
    except Exception as e:
        print(f"âš ï¸  Automation manager failed: {e}")
    
    return True

def main():
    """Run all tests"""
    print("="*60)
    print("ğŸš€ Enhanced DevO Chat - System Test")
    print("="*60)
    
    results = []
    
    # Run tests
    results.append(("Basic Imports", test_basic_imports()))
    results.append(("Gemini API", test_gemini_api()))
    results.append(("Local AI", test_local_ai()))
    results.append(("Enhanced Chat", test_enhanced_chat()))
    results.append(("Automation", test_automation()))
    
    # Show results
    print("\n" + "="*60)
    print("ğŸ“Š Test Results Summary")
    print("="*60)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name:<20} {status}")
        if result:
            passed += 1
    
    print(f"\nTests passed: {passed}/{len(results)}")
    
    if passed == len(results):
        print("\nğŸ‰ All tests passed! Enhanced DevO Chat is ready to use.")
        print("\nğŸš€ Run with: python chat_enhanced.py")
        print("   Or use: launch_enhanced_chat.bat")
    else:
        print("\nâš ï¸  Some tests failed. Check installation and configuration.")
        print("\nğŸ’¡ Setup help:")
        print("   1. Run: python setup_enhanced.py")
        print("   2. Set GEMINI_API_KEY environment variable")
        print("   3. Install: pip install -r requirements_unified.txt")
    
    return passed == len(results)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
